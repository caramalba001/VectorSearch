{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from azure.cosmos import CosmosClient, PartitionKey\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from rapidfuzz import fuzz\n",
    "from pythainlp.transliterate import romanize\n",
    "from rapidfuzz.distance import Levenshtein\n",
    "import pandas as pd\n",
    "import json\n",
    "import uuid\n",
    "import torch\n",
    "import jellyfish\n",
    "\n",
    "# Initialize the Cosmos client\n",
    "cosmos_url = \"YOUR_COSMOS_URL\"\n",
    "cosmos_key = \"YOUR_COSMOS_KEY\"\n",
    "database_name = \"YOUR_DATABASE_NAME\"\n",
    "container_name = \"YOUR_CONTAINER_NAME\"\n",
    "\n",
    "client_cosmos = CosmosClient(cosmos_url, cosmos_key)\n",
    "\n",
    "database = client_cosmos.create_database_if_not_exists(id=database_name)\n",
    "\n",
    "container = database.create_container_if_not_exists(\n",
    "    id=container_name,\n",
    "    partition_key=PartitionKey(path=\"/id\"),\n",
    ")\n",
    "\n",
    "print(\"Container created successfully in a serverless account.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DT = pd.read_parquet('YOUR_PATH')\n",
    "\n",
    "# Batch Run with Lavenstein\n",
    "model_name = \"intfloat/multilingual-e5-large\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModel.from_pretrained(model_name)\n",
    "\n",
    "def get_embedding(texts, tokenizer, model):\n",
    "    if isinstance(texts, pd.Series):\n",
    "        texts = texts.tolist()\n",
    "    elif isinstance(texts, str):\n",
    "        texts = [texts]\n",
    "    else:\n",
    "        texts = list(texts)  \n",
    "\n",
    "    inputs = tokenizer(texts, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "    with torch.no_grad():\n",
    "        embeddings = model(**inputs).last_hidden_state.mean(dim=1)\n",
    "    return embeddings.tolist()\n",
    "\n",
    "def run_query(query_embedding):\n",
    "    query_embedding_str = json.dumps(query_embedding)\n",
    "    results = container.query_items(\n",
    "        query=f'''\n",
    "        SELECT TOP 1 c.uuid, c.id_card, c.full_name, VectorDistance(c.embedding ,{query_embedding_str}) AS SimilarityScore  \n",
    "        FROM c \n",
    "        ORDER BY VectorDistance(c.embedding,{query_embedding_str})\n",
    "        ''',\n",
    "        enable_cross_partition_query=True, \n",
    "        populate_query_metrics=False, \n",
    "        populate_index_metrics=False\n",
    "    )\n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "def vector_search_batch(inputs):\n",
    "    if isinstance(inputs, pd.Series):\n",
    "        inputs = inputs.tolist()\n",
    "    else:\n",
    "        inputs = list(inputs)\n",
    "\n",
    "    embeddings = get_embedding(inputs, tokenizer, model)\n",
    "    embeddings_json = embeddings\n",
    "\n",
    "    results_list = [None]*len(inputs)\n",
    "    total = len(inputs)\n",
    "    completed = 0\n",
    "\n",
    "    with ThreadPoolExecutor() as executor:\n",
    "        futures = {executor.submit(run_query, emb): i for i, emb in enumerate(embeddings_json)}\n",
    "        for future in as_completed(futures):\n",
    "            i = futures[future]\n",
    "            results_list[i] = future.result()\n",
    "            completed += 1\n",
    "            print(f\"Completed {completed}/{total} records\")\n",
    "\n",
    "    return results_list\n",
    "\n",
    "def calculate_levenshtein_distance_optimized(inputs):\n",
    "    vector_search_results = vector_search_batch(inputs)\n",
    "\n",
    "    def process_result(input_name, result_df):\n",
    "        \"\"\"Process each input-result pair and calculate Levenshtein distance.\"\"\"\n",
    "        if result_df is not None and not result_df.empty:\n",
    "            # Calculate Levenshtein distance for each match\n",
    "            result_df['LevenshteinDistance'] = result_df['full_name'].apply(\n",
    "                lambda x: Levenshtein.distance(input_name, x)\n",
    "            )\n",
    "            # Add the input name for context\n",
    "            result_df['InputName'] = input_name\n",
    "        else:\n",
    "            # If no results, append a placeholder row\n",
    "            result_df = pd.DataFrame({\n",
    "                'uuid': [None],\n",
    "                'id_card': [None],\n",
    "                'full_name': [None],\n",
    "                'SimilarityScore': [None],\n",
    "                'LevenshteinDistance': [None],\n",
    "                'InputName': [input_name]\n",
    "            })\n",
    "        return result_df\n",
    "\n",
    "    results_with_distance = []\n",
    "    with ThreadPoolExecutor() as executor:\n",
    "        # Parallelize processing of results\n",
    "        futures = [\n",
    "            executor.submit(process_result, input_name, result_df)\n",
    "            for input_name, result_df in zip(inputs, vector_search_results)\n",
    "        ]\n",
    "        for future in futures:\n",
    "            results_with_distance.append(future.result())\n",
    "\n",
    "    # Combine all results into a single DataFrame\n",
    "    return pd.concat(results_with_distance, ignore_index=True)\n",
    "\n",
    "def calculate_levenshtein_distance(inputs):\n",
    "\n",
    "    vector_search_results = vector_search_batch(inputs)\n",
    "    results_with_distance = []\n",
    "\n",
    "    for input_name, result_df in zip(inputs, vector_search_results):\n",
    "        if result_df is not None and not result_df.empty:\n",
    "            result_df = result_df.copy()  # Avoid modifying the original result DataFrame\n",
    "            # Calculate Levenshtein distance for each match\n",
    "            result_df['LevenshteinDistance'] = result_df['full_name'].apply(\n",
    "                lambda x: Levenshtein.distance(input_name, x)\n",
    "            )\n",
    "\n",
    "            # Romanize the input_name once\n",
    "            input_romanize = romanize(input_name, engine=\"thai2rom\")\n",
    "\n",
    "            # Romanize the 'full_name' column once and store in 'Output_Romanize'\n",
    "            result_df['Output_Romanize'] = result_df['full_name'].apply(\n",
    "                lambda x: romanize(x, engine=\"thai2rom\")\n",
    "            )\n",
    "\n",
    "            # Add a single 'Input_Romanize' column with the same value for all rows\n",
    "            result_df['Input_Romanize'] = input_romanize\n",
    "\n",
    "            # Calculate Levenshtein distance between 'Input_Romanize' and 'Output_Romanize'\n",
    "            result_df['Score_Romanize'] = result_df['Output_Romanize'].apply(\n",
    "                lambda x: Levenshtein.distance(input_romanize, x)\n",
    "            )\n",
    "\n",
    "            # Add the input name for context\n",
    "            result_df['InputName'] = input_name\n",
    "            results_with_distance.append(result_df)\n",
    "        else:\n",
    "            # If no results, append a placeholder row\n",
    "            results_with_distance.append(pd.DataFrame({\n",
    "                'uuid': [None],\n",
    "                'id_card': [None],\n",
    "                'full_name': [None],\n",
    "                'SimilarityScore': [None],\n",
    "                'LevenshteinDistance': [None],\n",
    "                'InputName': [input_name]\n",
    "            }))\n",
    "\n",
    "    # Combine all results into a single DataFrame\n",
    "    return pd.concat(results_with_distance, ignore_index=True)\n",
    "\n",
    "# Now calling this function will print progress as queries complete\n",
    "DF = calculate_levenshtein_distance(DT['full_name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the conditions and assign 'Label' and 'Case'\n",
    "DF.loc[DF['SimilarityScore'] >= 0.99, ['Label', 'Case']] = ['Same Person', 1]\n",
    "\n",
    "DF.loc[\n",
    "    (DF['SimilarityScore'] < 0.99) & (DF['LevenshteinDistance'] == 1) & (DF['Score_Romanize'].isin([0, 1])),\n",
    "    ['Label', 'Case']\n",
    "] = ['Same Person', 2]\n",
    "\n",
    "DF.loc[\n",
    "    (DF['SimilarityScore'] < 0.99) & (DF['LevenshteinDistance'] == 1) & (~DF['Score_Romanize'].isin([0, 1])),\n",
    "    ['Label', 'Case']\n",
    "] = ['Not Sure', 3]\n",
    "\n",
    "DF.loc[\n",
    "    (DF['SimilarityScore'] < 0.99) & (DF['LevenshteinDistance'] == 2) & (DF['Score_Romanize'] == 0),\n",
    "    ['Label', 'Case']\n",
    "] = ['Same Person', 4]\n",
    "\n",
    "DF.loc[\n",
    "    (DF['SimilarityScore'] < 0.99) & (DF['LevenshteinDistance'] == 2) & (DF['Score_Romanize'].isin([1, 2, 3])),\n",
    "    ['Label', 'Case']\n",
    "] = ['Not Sure', 5]\n",
    "\n",
    "DF.loc[\n",
    "    (DF['SimilarityScore'] < 0.99) & (DF['LevenshteinDistance'] == 2) & (~DF['Score_Romanize'].isin([0, 1, 2, 3])),\n",
    "    ['Label', 'Case']\n",
    "] = ['Different Person', 6]\n",
    "\n",
    "DF.loc[\n",
    "    (DF['SimilarityScore'] < 0.99) & (DF['LevenshteinDistance'] == 3) & (DF['Score_Romanize'] == 0),\n",
    "    ['Label', 'Case']\n",
    "] = ['Same Person', 7]\n",
    "\n",
    "DF.loc[\n",
    "    (DF['SimilarityScore'] < 0.99) & (DF['LevenshteinDistance'] == 3) & (DF['Score_Romanize'].isin([1, 2, 3])),\n",
    "    ['Label', 'Case']\n",
    "] = ['Not Sure', 8]\n",
    "\n",
    "DF.loc[\n",
    "    (DF['SimilarityScore'] < 0.99) & (DF['LevenshteinDistance'] == 3) & (~DF['Score_Romanize'].isin([1, 2, 3])),\n",
    "    ['Label', 'Case']\n",
    "] = ['Different Person', 9]\n",
    "\n",
    "DF.loc[\n",
    "    (DF['SimilarityScore'] < 0.99) & (DF['LevenshteinDistance'] == 4) & (DF['Score_Romanize'].isin([0, 1])),\n",
    "    ['Label', 'Case']\n",
    "] = ['Not Sure', 10]\n",
    "\n",
    "DF.loc[\n",
    "    (DF['SimilarityScore'] < 0.99) & (DF['LevenshteinDistance'] == 4) & (~DF['Score_Romanize'].isin([0, 1])),\n",
    "    ['Label', 'Case']\n",
    "] = ['Different Person', 11]\n",
    "\n",
    "DF.loc[\n",
    "    (DF['SimilarityScore'] < 0.99) & (DF['LevenshteinDistance'] >= 5),\n",
    "    ['Label', 'Case']\n",
    "] = ['Different Person', 12]\n",
    "\n",
    "DF.to_excel('result.xlsx')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
